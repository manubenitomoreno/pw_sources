{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory logit models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from shapely.wkt import loads\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.font_manager\n",
    "import seaborn as sn\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "\n",
    "\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "\n",
    "\n",
    "#matplotlib.font_manager.findSystemFonts(fontpaths=None, fontext='ttf')\n",
    "sn.set_style(\"white\")\n",
    "\n",
    "from scipy.spatial import cKDTree\n",
    "\n",
    "csfont = {'fontname':'Adobe Garamond Pro','fontsize':30}\n",
    "hfont = {'fontname':'Adobe Garamond Pro','fontsize':12}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and prepare dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1500 = pd.read_parquet(r\"../data/extraction_1500.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_testlogit = ds_1500[['elevator','trip_purpose', 'trip_distance', 'trip_mode', 'dem_gender', 'dem_income','dem_age','dem_education', 'dem_activity', 'dem_hou_size','acc_shopping_market', 'acc_shopping_alone']]\n",
    "df_testlogit = df_testlogit[df_testlogit['dem_income'].notnull()]\n",
    "for v in ['acc_shopping_market', 'acc_shopping_alone']:\n",
    "    df_testlogit[v] = df_testlogit[v].fillna(0)\n",
    "df_testlogit['acc_shopping'] = df_testlogit['acc_shopping_alone'] + df_testlogit['acc_shopping_market']\n",
    "df_testlogit = df_testlogit.drop(columns = ['acc_shopping_market', 'acc_shopping_alone'])\n",
    "df_testlogit = df_testlogit[df_testlogit['trip_purpose'] == 'Shopping']\n",
    "df_testlogit['dem_education'] = df_testlogit['dem_education'].map({'Second - B':3, 'First':1, 'Third':4, 'Second - A':2, 'No':0})\n",
    "df_testlogit['dem_activity'] = df_testlogit['dem_activity'].map({'Retired':0, 'Caretaker':1, 'Unemployed':0, 'Worker':1, 'Student':1})\n",
    "df_testlogit['dem_gender'] = df_testlogit['dem_gender'].map({'Female':0,'Male':1})\n",
    "df_testlogit = df_testlogit[df_testlogit['trip_mode'] != 'Other']\n",
    "df_testlogit['trip_mode'] = df_testlogit['trip_mode'].map({'Walking':'active', 'Motor - Personal':'driving', 'Bus':'transit', 'Cycling':'active', 'Train':'transit','Motor - Shared':'driving'})\n",
    "df_testlogit = df_testlogit[(df_testlogit['dem_age']>=18)&(df_testlogit['dem_age']<=65)]\n",
    "df_testlogit = df_testlogit[df_testlogit['trip_mode'].isin(['active','driving'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further filtering model parametes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Driving age\n",
    "data_filtered = df_testlogit[(df_testlogit['dem_age'] >= 18) & (df_testlogit['dem_age'] <= 65)]\n",
    "# Balance the `trip_mode` column\n",
    "active = data_filtered[data_filtered['trip_mode'] == 'active']\n",
    "driving = data_filtered[data_filtered['trip_mode'] == 'driving']\n",
    "# Resample the minority class to balance the dataset\n",
    "min_class_count = min(len(active), len(driving))\n",
    "active_resampled = resample(active, replace=False, n_samples=min_class_count, random_state=42)\n",
    "driving_resampled = resample(driving, replace=False, n_samples=min_class_count, random_state=42)\n",
    "# Combine the balanced dataset\n",
    "data_filtered = pd.concat([active_resampled, driving_resampled])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a model without distance contraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Define features and target variable\n",
    "features = ['trip_distance', 'dem_gender', 'dem_income', 'dem_age','dem_education', 'dem_activity', 'dem_hou_size', 'acc_shopping']\n",
    "target = 'trip_mode'\n",
    "# Encode the target variable: 'active' -> 0, 'driving' -> 1\n",
    "data_filtered['trip_mode_encoded'] = data_filtered['trip_mode'].map({'active': 0, 'driving': 1})\n",
    "# Step 2: Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "data_filtered[features] = scaler.fit_transform(data_filtered[features])\n",
    "# Step 3: Split into training and testing sets\n",
    "X = data_filtered[features]\n",
    "y = data_filtered['trip_mode_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "# Add a constant term for the intercept in the model\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the Binomial Logit Model using the training data and weights\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "result.summary()\n",
    "\n",
    "# Prepare test data with a constant term\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_prob = result.predict(X_test_const)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as threshold\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Extract coefficients and their confidence intervals\n",
    "coefficients = result.params\n",
    "conf_intervals = result.conf_int()\n",
    "features_with_const = ['Intercept'] + features  # Include the constant term\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "impact_df = pd.DataFrame({\n",
    "    'Feature': features_with_const,\n",
    "    'Coefficient': coefficients.values,\n",
    "    'Lower CI': conf_intervals[0].values,\n",
    "    'Upper CI': conf_intervals[1].values\n",
    "}).set_index('Feature')\n",
    "\n",
    "# Sort by absolute coefficient values for better visualization\n",
    "impact_df['Abs Coefficient'] = np.abs(impact_df['Coefficient'])\n",
    "impact_df = impact_df.sort_values(by='Abs Coefficient', ascending=False)\n",
    "\n",
    "# Plot feature impacts with confidence intervals\n",
    "plt.figure(figsize=(8.5, 6))\n",
    "plt.errorbar(\n",
    "    impact_df.index, impact_df['Coefficient'], \n",
    "    yerr=(impact_df['Coefficient'] - impact_df['Lower CI'], impact_df['Upper CI'] - impact_df['Coefficient']),\n",
    "    fmt='o', capsize=5, label=\"Coefficient ± CI\",color='r'\n",
    ")\n",
    "plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Feature Impact on Mode Choice\\nNo Distance Threshold',**csfont)\n",
    "plt.ylabel('Coefficient',**hfont)\n",
    "plt.xlabel('Feature',**hfont)\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"../figures/17a_variable_importance_logit.jpg\")\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Add a constant term for the intercept\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the Binomial Logit Model\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a model with distance contraints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Filter dataset for valid rows\n",
    "data_filtered = df_testlogit[(df_testlogit['dem_age'] >= 18) & (df_testlogit['dem_age'] <= 65)]\n",
    "data_filtered = data_filtered[data_filtered['trip_distance']<1.5]\n",
    "# Step 2: Balance the `trip_mode` column\n",
    "active = data_filtered[data_filtered['trip_mode'] == 'active']\n",
    "driving = data_filtered[data_filtered['trip_mode'] == 'driving']\n",
    "# Resample the minority class to balance the dataset\n",
    "min_class_count = min(len(active), len(driving))\n",
    "active_resampled = resample(active, replace=False, n_samples=min_class_count, random_state=42)\n",
    "driving_resampled = resample(driving, replace=False, n_samples=min_class_count, random_state=42)\n",
    "# Combine the balanced dataset\n",
    "data_filtered = pd.concat([active_resampled, driving_resampled])\n",
    "\n",
    "# Step 1: Define features and target variable\n",
    "features = ['trip_distance', 'dem_gender', 'dem_income', 'dem_age','dem_education', 'dem_activity', 'dem_hou_size', 'acc_shopping']\n",
    "target = 'trip_mode'\n",
    "# Encode the target variable: 'active' -> 0, 'driving' -> 1\n",
    "data_filtered['trip_mode_encoded'] = data_filtered['trip_mode'].map({'active': 0, 'driving': 1})\n",
    "# Step 2: Scale numeric features\n",
    "scaler = StandardScaler()\n",
    "data_filtered[features] = scaler.fit_transform(data_filtered[features])\n",
    "# Step 3: Split into training and testing sets\n",
    "X = data_filtered[features]\n",
    "y = data_filtered['trip_mode_encoded']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=42\n",
    ")\n",
    "\n",
    "# Display the shape of the training and testing sets\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape\n",
    "\n",
    "# Add a constant term for the intercept in the model\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the Binomial Logit Model using the training data and weights\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "result = logit_model.fit()\n",
    "\n",
    "# Display the summary of the model\n",
    "result.summary()\n",
    "\n",
    "# Prepare test data with a constant term\n",
    "X_test_const = sm.add_constant(X_test)\n",
    "\n",
    "# Predict probabilities for the test set\n",
    "y_pred_prob = result.predict(X_test_const)\n",
    "\n",
    "# Convert probabilities to binary predictions using 0.5 as threshold\n",
    "y_pred = (y_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate model performance\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, y_pred_prob)\n",
    "\n",
    "# Extract coefficients and their confidence intervals\n",
    "coefficients = result.params\n",
    "conf_intervals = result.conf_int()\n",
    "features_with_const = ['Intercept'] + features  # Include the constant term\n",
    "\n",
    "# Create a DataFrame for visualization\n",
    "impact_df = pd.DataFrame({\n",
    "    'Feature': features_with_const,\n",
    "    'Coefficient': coefficients.values,\n",
    "    'Lower CI': conf_intervals[0].values,\n",
    "    'Upper CI': conf_intervals[1].values\n",
    "}).set_index('Feature')\n",
    "\n",
    "# Sort by absolute coefficient values for better visualization\n",
    "impact_df['Abs Coefficient'] = np.abs(impact_df['Coefficient'])\n",
    "impact_df = impact_df.sort_values(by='Abs Coefficient', ascending=False)\n",
    "\n",
    "# Plot feature impacts with confidence intervals\n",
    "plt.figure(figsize=(8.5, 6))\n",
    "plt.errorbar(\n",
    "    impact_df.index, impact_df['Coefficient'], \n",
    "    yerr=(impact_df['Coefficient'] - impact_df['Lower CI'], impact_df['Upper CI'] - impact_df['Coefficient']),\n",
    "    fmt='o', capsize=5, label=\"Coefficient ± CI\",color='r'\n",
    ")\n",
    "plt.axhline(0, color='gray', linestyle='--', linewidth=0.8)\n",
    "plt.xticks(rotation=45)\n",
    "plt.title('Feature Impact on Mode Choice\\n1500 m Threshold',**csfont)\n",
    "plt.ylabel('Coefficient',**hfont)\n",
    "plt.xlabel('Feature',**hfont)\n",
    "plt.tight_layout()\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig(r\"../figures/17b_variable_importance_logit_proximity.jpg\")\n",
    "plt.show()\n",
    "\n",
    "# Add a constant term for the intercept\n",
    "X_train_const = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the Binomial Logit Model\n",
    "logit_model = sm.Logit(y_train, X_train_const)\n",
    "result = logit_model.fit()\n",
    "\n",
    "print(result.summary())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
